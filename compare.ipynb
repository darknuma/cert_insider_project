{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab24ad31",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Implementing Existing Research Methodologies on Your Survey Data\n",
    "This addresses your supervisor's requirement to compare against actual research systems\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "class ExistingSystemsComparator:\n",
    "    \"\"\"\n",
    "    Compare your proposed method against existing research methodologies\n",
    "    using YOUR survey data consistently across all methods\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_path):\n",
    "        self.data_path = data_path\n",
    "        self.X, self.y = self._load_your_survey_data()\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = None, None, None, None\n",
    "        self.results = {}\n",
    "        \n",
    "    def _load_your_survey_data(self):\n",
    "        \"\"\"Load and preprocess YOUR survey data consistently\"\"\"\n",
    "        df = pd.read_csv(self.data_path)\n",
    "        \n",
    "        # Your survey data preprocessing\n",
    "        df['encountered_threat_binary'] = df['encountered_threat'].map({\n",
    "            'Yes': 1, 'No': 0, 'Not sure': 0\n",
    "        })\n",
    "        \n",
    "        # Select relevant features from your survey\n",
    "        features = [\n",
    "            'remote_experience', 'work_location', 'flexible_hours', \n",
    "            'data_access_frequency', 'threat_concern', \n",
    "            'detection_confidence', 'tools_effectiveness'\n",
    "        ]\n",
    "        \n",
    "        # Add categorical features if they exist in your data\n",
    "        categorical_features = [\n",
    "            'industry_Finance', 'industry_Healthcare', 'industry_Technology'\n",
    "        ]\n",
    "        \n",
    "        # Only include features that exist in your dataset\n",
    "        available_features = []\n",
    "        for feature in features + categorical_features:\n",
    "            if feature in df.columns:\n",
    "                available_features.append(feature)\n",
    "        \n",
    "        X = df[available_features].fillna(0)\n",
    "        y = df['encountered_threat_binary']\n",
    "        \n",
    "        print(f\"Dataset loaded: {X.shape[0]} samples, {X.shape[1]} features\")\n",
    "        print(f\"Threat distribution: {y.value_counts().to_dict()}\")\n",
    "        \n",
    "        return X, y\n",
    "    \n",
    "    def prepare_data_split(self, test_size=0.2, random_state=42):\n",
    "        \"\"\"Prepare consistent train/test split for all methods\"\"\"\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(\n",
    "            self.X, self.y, test_size=test_size, random_state=random_state, \n",
    "            stratify=self.y if self.y.nunique() > 1 else None\n",
    "        )\n",
    "        \n",
    "        print(f\"Train set: {self.X_train.shape[0]} samples\")\n",
    "        print(f\"Test set: {self.X_test.shape[0]} samples\")\n",
    "        print(f\"Train threats: {self.y_train.sum()}/{len(self.y_train)}\")\n",
    "        print(f\"Test threats: {self.y_test.sum()}/{len(self.y_test)}\")\n",
    "\n",
    "    def implement_han_et_al_method(self):\n",
    "        \"\"\"\n",
    "        Implementation of Han et al. (2023) methodology\n",
    "        \"A Study on Detection of Malicious Behavior Based on Host Process Data Using Machine Learning\"\n",
    "        \n",
    "        Key aspects: KNN, NB, RF with SMOTE preprocessing and PCA\n",
    "        \"\"\"\n",
    "        print(\"\\n=== Implementing Han et al. (2023) Method ===\")\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(self.X_train)\n",
    "        X_test_scaled = scaler.transform(self.X_test)\n",
    "        \n",
    "        # Apply SMOTE preprocessing as described in their paper\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train_scaled, self.y_train)\n",
    "        \n",
    "        print(f\"After SMOTE: {X_train_smote.shape[0]} samples\")\n",
    "        print(f\"Class distribution: {np.bincount(y_train_smote)}\")\n",
    "        \n",
    "        # Apply PCA dimensionality reduction\n",
    "        pca = PCA(n_components=0.95, random_state=42)\n",
    "        X_train_pca = pca.fit_transform(X_train_smote)\n",
    "        X_test_pca = pca.transform(X_test_scaled)\n",
    "        \n",
    "        print(f\"PCA components: {X_train_pca.shape[1]} (from {X_train_scaled.shape[1]})\")\n",
    "        \n",
    "        # Models from Han et al. paper\n",
    "        han_models = {\n",
    "            'KNN_Han_et_al': KNeighborsClassifier(n_neighbors=5),\n",
    "            'NaiveBayes_Han_et_al': GaussianNB(),\n",
    "            'RandomForest_Han_et_al': RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        }\n",
    "        \n",
    "        han_results = {}\n",
    "        \n",
    "        for model_name, model in han_models.items():\n",
    "            print(f\"Training {model_name}...\")\n",
    "            \n",
    "            model.fit(X_train_pca, y_train_smote)\n",
    "            y_pred = model.predict(X_test_pca)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = self._calculate_metrics(self.y_test, y_pred)\n",
    "            han_results[model_name] = metrics\n",
    "            \n",
    "            print(f\"  Results: Acc={metrics['accuracy']:.3f}, \"\n",
    "                  f\"Prec={metrics['precision']:.3f}, \"\n",
    "                  f\"Rec={metrics['recall']:.3f}, \"\n",
    "                  f\"F1={metrics['f1']:.3f}\")\n",
    "        \n",
    "        self.results.update(han_results)\n",
    "        return han_results\n",
    "    \n",
    "    def implement_janjua_et_al_method(self):\n",
    "        \"\"\"\n",
    "        Implementation of Janjua et al. (2020) methodology\n",
    "        \"Handling insider threat through supervised machine learning techniques\"\n",
    "        \n",
    "        Key aspects: AdaBoost, SVM, NB, LR, KNN for behavioral classification\n",
    "        \"\"\"\n",
    "        print(\"\\n=== Implementing Janjua et al. (2020) Method ===\")\n",
    "        \n",
    "        # Scale features as per their methodology\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(self.X_train)\n",
    "        X_test_scaled = scaler.transform(self.X_test)\n",
    "        \n",
    "        # Models from Janjua et al. paper\n",
    "        janjua_models = {\n",
    "            'AdaBoost_Janjua_et_al': AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "            'SVM_Janjua_et_al': SVC(kernel='rbf', random_state=42),\n",
    "            'NaiveBayes_Janjua_et_al': GaussianNB(),\n",
    "            'KNN_Janjua_et_al': KNeighborsClassifier(n_neighbors=5)\n",
    "        }\n",
    "        \n",
    "        janjua_results = {}\n",
    "        \n",
    "        for model_name, model in janjua_models.items():\n",
    "            print(f\"Training {model_name}...\")\n",
    "            \n",
    "            model.fit(X_train_scaled, self.y_train)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = self._calculate_metrics(self.y_test, y_pred)\n",
    "            janjua_results[model_name] = metrics\n",
    "            \n",
    "            print(f\"  Results: Acc={metrics['accuracy']:.3f}, \"\n",
    "                  f\"Prec={metrics['precision']:.3f}, \"\n",
    "                  f\"Rec={metrics['recall']:.3f}, \"\n",
    "                  f\"F1={metrics['f1']:.3f}\")\n",
    "        \n",
    "        self.results.update(janjua_results)\n",
    "        return janjua_results\n",
    "    \n",
    "    def implement_mehmood_et_al_method(self):\n",
    "        \"\"\"\n",
    "        Implementation of Mehmood et al. (2023) methodology\n",
    "        \"Privilege Escalation Attack Detection and Mitigation in Cloud using Machine Learning\"\n",
    "        \n",
    "        Key aspects: Ensemble learning with RF, AdaBoost, XGBoost, LightGBM\n",
    "        \"\"\"\n",
    "        print(\"\\n=== Implementing Mehmood et al. (2023) Method ===\")\n",
    "        \n",
    "        # Models from Mehmood et al. paper with their reported performance focus\n",
    "        mehmood_models = {\n",
    "            'RandomForest_Mehmood_et_al': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "            'AdaBoost_Mehmood_et_al': AdaBoostClassifier(n_estimators=100, random_state=42),\n",
    "            'XGBoost_Mehmood_et_al': xgb.XGBClassifier(random_state=42, eval_metric='logloss'),\n",
    "            'LightGBM_Mehmood_et_al': lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
    "        }\n",
    "        \n",
    "        mehmood_results = {}\n",
    "        \n",
    "        for model_name, model in mehmood_models.items():\n",
    "            print(f\"Training {model_name}...\")\n",
    "            \n",
    "            model.fit(self.X_train, self.y_train)\n",
    "            y_pred = model.predict(self.X_test)\n",
    "            \n",
    "            # Calculate metrics\n",
    "            metrics = self._calculate_metrics(self.y_test, y_pred)\n",
    "            mehmood_results[model_name] = metrics\n",
    "            \n",
    "            print(f\"  Results: Acc={metrics['accuracy']:.3f}, \"\n",
    "                  f\"Prec={metrics['precision']:.3f}, \"\n",
    "                  f\"Rec={metrics['recall']:.3f}, \"\n",
    "                  f\"F1={metrics['f1']:.3f}\")\n",
    "        \n",
    "        self.results.update(mehmood_results)\n",
    "        return mehmood_results\n",
    "    \n",
    "    def implement_your_proposed_method(self):\n",
    "        \"\"\"\n",
    "        Implement YOUR proposed hybrid ensemble method\n",
    "        This should be your novel contribution combining supervised + unsupervised + deep learning\n",
    "        \"\"\"\n",
    "        print(\"\\n=== Implementing Your Proposed Method ===\")\n",
    "        \n",
    "        # Scale features\n",
    "        scaler = StandardScaler()\n",
    "        X_train_scaled = scaler.fit_transform(self.X_train)\n",
    "        X_test_scaled = scaler.transform(self.X_test)\n",
    "        \n",
    "        # Your hybrid approach components\n",
    "        # Component 1: Supervised learning\n",
    "        rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "        rf_model.fit(X_train_scaled, self.y_train)\n",
    "        rf_pred_proba = rf_model.predict_proba(X_test_scaled)[:, 1]\n",
    "        \n",
    "        # Component 2: Ensemble of multiple algorithms\n",
    "        gb_model = lgb.LGBMClassifier(random_state=42, verbose=-1)\n",
    "        gb_model.fit(X_train_scaled, self.y_train)\n",
    "        gb_pred_proba = gb_model.predict_proba(X_test_scaled)[:, 1]\n",
    "        \n",
    "        # Component 3: AdaBoost for behavioral patterns\n",
    "        ada_model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
    "        ada_model.fit(X_train_scaled, self.y_train)\n",
    "        ada_pred_proba = ada_model.predict_proba(X_test_scaled)[:, 1]\n",
    "        \n",
    "        # Hybrid ensemble combination (your novel approach)\n",
    "        # Weighted combination based on performance\n",
    "        ensemble_proba = (0.4 * rf_pred_proba + 0.35 * gb_pred_proba + 0.25 * ada_pred_proba)\n",
    "        \n",
    "        # Convert to binary predictions\n",
    "        threshold = 0.5\n",
    "        ensemble_pred = (ensemble_proba > threshold).astype(int)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = self._calculate_metrics(self.y_test, ensemble_pred)\n",
    "        \n",
    "        proposed_results = {'Proposed_Hybrid_Model': metrics}\n",
    "        \n",
    "        print(f\"Proposed Model Results: Acc={metrics['accuracy']:.3f}, \"\n",
    "              f\"Prec={metrics['precision']:.3f}, \"\n",
    "              f\"Rec={metrics['recall']:.3f}, \"\n",
    "              f\"F1={metrics['f1']:.3f}\")\n",
    "        \n",
    "        self.results.update(proposed_results)\n",
    "        return proposed_results\n",
    "    \n",
    "    def _calculate_metrics(self, y_true, y_pred):\n",
    "        \"\"\"Calculate standard evaluation metrics\"\"\"\n",
    "        return {\n",
    "            'accuracy': accuracy_score(y_true, y_pred),\n",
    "            'precision': precision_score(y_true, y_pred, zero_division=0),\n",
    "            'recall': recall_score(y_true, y_pred, zero_division=0),\n",
    "            'f1': f1_score(y_true, y_pred, zero_division=0)\n",
    "        }\n",
    "    \n",
    "    def create_comprehensive_comparison_table(self):\n",
    "        \"\"\"Create the comparison table your supervisor wants\"\"\"\n",
    "        print(\"\\n=== COMPREHENSIVE COMPARISON TABLE ===\")\n",
    "        print(\"Comparing Existing Research Methods vs Your Proposed Method\")\n",
    "        print(\"All methods tested on YOUR survey data for fair comparison\\n\")\n",
    "        \n",
    "        # Organize results by paper/method\n",
    "        comparison_data = []\n",
    "        \n",
    "        for method_name, metrics in self.results.items():\n",
    "            # Extract paper reference\n",
    "            if 'Han_et_al' in method_name:\n",
    "                paper_ref = 'Han et al. (2023)'\n",
    "            elif 'Janjua_et_al' in method_name:\n",
    "                paper_ref = 'Janjua et al. (2020)'\n",
    "            elif 'Mehmood_et_al' in method_name:\n",
    "                paper_ref = 'Mehmood et al. (2023)'\n",
    "            elif 'Proposed' in method_name:\n",
    "                paper_ref = 'Your Research (2024)'\n",
    "            else:\n",
    "                paper_ref = 'Other Method'\n",
    "            \n",
    "            comparison_data.append({\n",
    "                'Paper_Reference': paper_ref,\n",
    "                'Method_Name': method_name,\n",
    "                'Accuracy': metrics['accuracy'],\n",
    "                'Precision': metrics['precision'],\n",
    "                'Recall': metrics['recall'],\n",
    "                'F1_Score': metrics['f1']\n",
    "            })\n",
    "        \n",
    "        # Create DataFrame and sort by F1-score\n",
    "        comparison_df = pd.DataFrame(comparison_data)\n",
    "        comparison_df = comparison_df.sort_values('F1_Score', ascending=False)\n",
    "        \n",
    "        # Display formatted table\n",
    "        print(comparison_df.to_string(index=False, float_format='%.3f'))\n",
    "        \n",
    "        # Highlight your method's performance\n",
    "        your_method = comparison_df[comparison_df['Method_Name'].str.contains('Proposed')]\n",
    "        if not your_method.empty:\n",
    "            your_rank = comparison_df.index[comparison_df['Method_Name'].str.contains('Proposed')].tolist()[0] + 1\n",
    "            print(f\"\\nYour Proposed Method Ranking: {your_rank} out of {len(comparison_df)} methods\")\n",
    "            print(f\"Your F1-Score: {your_method.iloc[0]['F1_Score']:.3f}\")\n",
    "        \n",
    "        return comparison_df\n",
    "    \n",
    "    def run_complete_comparison(self):\n",
    "        \"\"\"Run complete comparison as required by your supervisor\"\"\"\n",
    "        print(\"=== RUNNING COMPLETE EXISTING SYSTEMS COMPARISON ===\")\n",
    "        print(\"This implements actual research methodologies from your literature review\")\n",
    "        print(\"on YOUR survey data for fair comparison\\n\")\n",
    "        \n",
    "        # Prepare data\n",
    "        self.prepare_data_split()\n",
    "        \n",
    "        # Run all existing methods\n",
    "        han_results = self.implement_han_et_al_method()\n",
    "        janjua_results = self.implement_janjua_et_al_method()  \n",
    "        mehmood_results = self.implement_mehmood_et_al_method()\n",
    "        \n",
    "        # Run your proposed method\n",
    "        proposed_results = self.implement_your_proposed_method()\n",
    "        \n",
    "        # Create comprehensive comparison\n",
    "        comparison_table = self.create_comprehensive_comparison_table()\n",
    "        \n",
    "        return comparison_table, self.results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27823919",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Main function to run the complete existing systems comparison\n",
    "\"\"\"\n",
    "# Replace with your actual data path\n",
    "DATA_PATH = \"preprocessed_data.csv\"\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7185f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 400 samples, 10 features\n",
      "Threat distribution: {0: 331, 1: 69}\n"
     ]
    }
   ],
   "source": [
    "    # Initialize comparator\n",
    "comparator = ExistingSystemsComparator(DATA_PATH)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85d24d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RUNNING COMPLETE EXISTING SYSTEMS COMPARISON ===\n",
      "This implements actual research methodologies from your literature review\n",
      "on YOUR survey data for fair comparison\n",
      "\n",
      "Train set: 320 samples\n",
      "Test set: 80 samples\n",
      "Train threats: 55/320\n",
      "Test threats: 14/80\n",
      "\n",
      "=== Implementing Han et al. (2023) Method ===\n",
      "After SMOTE: 530 samples\n",
      "Class distribution: [265 265]\n",
      "PCA components: 10 (from 10)\n",
      "Training KNN_Han_et_al...\n",
      "  Results: Acc=0.562, Prec=0.138, Rec=0.286, F1=0.186\n",
      "Training NaiveBayes_Han_et_al...\n",
      "  Results: Acc=0.525, Prec=0.071, Rec=0.143, F1=0.095\n",
      "Training RandomForest_Han_et_al...\n",
      "  Results: Acc=0.775, Prec=0.300, Rec=0.214, F1=0.250\n",
      "\n",
      "=== Implementing Janjua et al. (2020) Method ===\n",
      "Training AdaBoost_Janjua_et_al...\n",
      "  Results: Acc=0.812, Prec=0.000, Rec=0.000, F1=0.000\n",
      "Training SVM_Janjua_et_al...\n",
      "  Results: Acc=0.825, Prec=0.000, Rec=0.000, F1=0.000\n",
      "Training NaiveBayes_Janjua_et_al...\n",
      "  Results: Acc=0.750, Prec=0.000, Rec=0.000, F1=0.000\n",
      "Training KNN_Janjua_et_al...\n",
      "  Results: Acc=0.800, Prec=0.000, Rec=0.000, F1=0.000\n",
      "\n",
      "=== Implementing Mehmood et al. (2023) Method ===\n",
      "Training RandomForest_Mehmood_et_al...\n",
      "  Results: Acc=0.812, Prec=0.000, Rec=0.000, F1=0.000\n",
      "Training AdaBoost_Mehmood_et_al...\n",
      "  Results: Acc=0.812, Prec=0.000, Rec=0.000, F1=0.000\n",
      "Training XGBoost_Mehmood_et_al...\n",
      "  Results: Acc=0.800, Prec=0.250, Rec=0.071, F1=0.111\n",
      "Training LightGBM_Mehmood_et_al...\n",
      "  Results: Acc=0.800, Prec=0.250, Rec=0.071, F1=0.111\n",
      "\n",
      "=== Implementing Your Proposed Method ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/emmanuel/Documents/cyber/.venv/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proposed Model Results: Acc=0.800, Prec=0.000, Rec=0.000, F1=0.000\n",
      "\n",
      "=== COMPREHENSIVE COMPARISON TABLE ===\n",
      "Comparing Existing Research Methods vs Your Proposed Method\n",
      "All methods tested on YOUR survey data for fair comparison\n",
      "\n",
      "      Paper_Reference                Method_Name  Accuracy  Precision  Recall  F1_Score\n",
      "    Han et al. (2023)     RandomForest_Han_et_al     0.775      0.300   0.214     0.250\n",
      "    Han et al. (2023)              KNN_Han_et_al     0.562      0.138   0.286     0.186\n",
      "Mehmood et al. (2023)      XGBoost_Mehmood_et_al     0.800      0.250   0.071     0.111\n",
      "Mehmood et al. (2023)     LightGBM_Mehmood_et_al     0.800      0.250   0.071     0.111\n",
      "    Han et al. (2023)       NaiveBayes_Han_et_al     0.525      0.071   0.143     0.095\n",
      " Janjua et al. (2020)      AdaBoost_Janjua_et_al     0.812      0.000   0.000     0.000\n",
      " Janjua et al. (2020)           SVM_Janjua_et_al     0.825      0.000   0.000     0.000\n",
      " Janjua et al. (2020)    NaiveBayes_Janjua_et_al     0.750      0.000   0.000     0.000\n",
      " Janjua et al. (2020)           KNN_Janjua_et_al     0.800      0.000   0.000     0.000\n",
      "Mehmood et al. (2023) RandomForest_Mehmood_et_al     0.812      0.000   0.000     0.000\n",
      "Mehmood et al. (2023)     AdaBoost_Mehmood_et_al     0.812      0.000   0.000     0.000\n",
      " Your Research (2024)      Proposed_Hybrid_Model     0.800      0.000   0.000     0.000\n",
      "\n",
      "Your Proposed Method Ranking: 12 out of 12 methods\n",
      "Your F1-Score: 0.000\n"
     ]
    }
   ],
   "source": [
    "    # Run complete comparison\n",
    "comparison_table, all_results = comparator.run_complete_comparison()\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "001c99ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Save results\n",
    " comparison_table.to_csv('existing_systems_comparison.csv', index=False)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6905efed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparison complete! Results saved to 'existing_systems_comparison.csv'\n",
      "Total methods compared: 12\n"
     ]
    }
   ],
   "source": [
    "print(f\"\\nComparison complete! Results saved to 'existing_systems_comparison.csv'\")\n",
    "print(f\"Total methods compared: {len(all_results)}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c81a644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paper_Reference</th>\n",
       "      <th>Method_Name</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Han et al. (2023)</td>\n",
       "      <td>RandomForest_Han_et_al</td>\n",
       "      <td>0.7750</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Han et al. (2023)</td>\n",
       "      <td>KNN_Han_et_al</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.137931</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.186047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mehmood et al. (2023)</td>\n",
       "      <td>XGBoost_Mehmood_et_al</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mehmood et al. (2023)</td>\n",
       "      <td>LightGBM_Mehmood_et_al</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Han et al. (2023)</td>\n",
       "      <td>NaiveBayes_Han_et_al</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Janjua et al. (2020)</td>\n",
       "      <td>AdaBoost_Janjua_et_al</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Janjua et al. (2020)</td>\n",
       "      <td>SVM_Janjua_et_al</td>\n",
       "      <td>0.8250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Janjua et al. (2020)</td>\n",
       "      <td>NaiveBayes_Janjua_et_al</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Janjua et al. (2020)</td>\n",
       "      <td>KNN_Janjua_et_al</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Mehmood et al. (2023)</td>\n",
       "      <td>RandomForest_Mehmood_et_al</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mehmood et al. (2023)</td>\n",
       "      <td>AdaBoost_Mehmood_et_al</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Your Research (2024)</td>\n",
       "      <td>Proposed_Hybrid_Model</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Paper_Reference                 Method_Name  Accuracy  Precision  \\\n",
       "2       Han et al. (2023)      RandomForest_Han_et_al    0.7750   0.300000   \n",
       "0       Han et al. (2023)               KNN_Han_et_al    0.5625   0.137931   \n",
       "9   Mehmood et al. (2023)       XGBoost_Mehmood_et_al    0.8000   0.250000   \n",
       "10  Mehmood et al. (2023)      LightGBM_Mehmood_et_al    0.8000   0.250000   \n",
       "1       Han et al. (2023)        NaiveBayes_Han_et_al    0.5250   0.071429   \n",
       "3    Janjua et al. (2020)       AdaBoost_Janjua_et_al    0.8125   0.000000   \n",
       "4    Janjua et al. (2020)            SVM_Janjua_et_al    0.8250   0.000000   \n",
       "5    Janjua et al. (2020)     NaiveBayes_Janjua_et_al    0.7500   0.000000   \n",
       "6    Janjua et al. (2020)            KNN_Janjua_et_al    0.8000   0.000000   \n",
       "7   Mehmood et al. (2023)  RandomForest_Mehmood_et_al    0.8125   0.000000   \n",
       "8   Mehmood et al. (2023)      AdaBoost_Mehmood_et_al    0.8125   0.000000   \n",
       "11   Your Research (2024)       Proposed_Hybrid_Model    0.8000   0.000000   \n",
       "\n",
       "      Recall  F1_Score  \n",
       "2   0.214286  0.250000  \n",
       "0   0.285714  0.186047  \n",
       "9   0.071429  0.111111  \n",
       "10  0.071429  0.111111  \n",
       "1   0.142857  0.095238  \n",
       "3   0.000000  0.000000  \n",
       "4   0.000000  0.000000  \n",
       "5   0.000000  0.000000  \n",
       "6   0.000000  0.000000  \n",
       "7   0.000000  0.000000  \n",
       "8   0.000000  0.000000  \n",
       "11  0.000000  0.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparison_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5ce3baf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'KNN_Han_et_al': {'accuracy': 0.5625,\n",
       "  'precision': 0.13793103448275862,\n",
       "  'recall': 0.2857142857142857,\n",
       "  'f1': 0.18604651162790697},\n",
       " 'NaiveBayes_Han_et_al': {'accuracy': 0.525,\n",
       "  'precision': 0.07142857142857142,\n",
       "  'recall': 0.14285714285714285,\n",
       "  'f1': 0.09523809523809523},\n",
       " 'RandomForest_Han_et_al': {'accuracy': 0.775,\n",
       "  'precision': 0.3,\n",
       "  'recall': 0.21428571428571427,\n",
       "  'f1': 0.25},\n",
       " 'AdaBoost_Janjua_et_al': {'accuracy': 0.8125,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0},\n",
       " 'SVM_Janjua_et_al': {'accuracy': 0.825,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0},\n",
       " 'NaiveBayes_Janjua_et_al': {'accuracy': 0.75,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0},\n",
       " 'KNN_Janjua_et_al': {'accuracy': 0.8,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0},\n",
       " 'RandomForest_Mehmood_et_al': {'accuracy': 0.8125,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0},\n",
       " 'AdaBoost_Mehmood_et_al': {'accuracy': 0.8125,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0},\n",
       " 'XGBoost_Mehmood_et_al': {'accuracy': 0.8,\n",
       "  'precision': 0.25,\n",
       "  'recall': 0.07142857142857142,\n",
       "  'f1': 0.1111111111111111},\n",
       " 'LightGBM_Mehmood_et_al': {'accuracy': 0.8,\n",
       "  'precision': 0.25,\n",
       "  'recall': 0.07142857142857142,\n",
       "  'f1': 0.1111111111111111},\n",
       " 'Proposed_Hybrid_Model': {'accuracy': 0.8,\n",
       "  'precision': 0.0,\n",
       "  'recall': 0.0,\n",
       "  'f1': 0.0}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42749d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
